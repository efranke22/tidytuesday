---
title: 'Tidy Tuesday #4'
author: "Erin Franke"
output: 
  html_document:
    df_print: paged
    code_download: true
    theme: cerulean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error=TRUE, message=FALSE, warning=FALSE)
```

```{r libraries}
library(tidyverse)     
library(lubridate)    
library(ggthemes)      
library(readr)
library(scales)
library(maps)          # for map data
library(ggmap)         # for mapping points on maps
library(gplots)
```

```{r}
# Read in the data for the week - this is choice #1
tweets <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-06-15/tweets.csv')
conjugal <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-02-16/conjugal.csv')
```

### Plot One: Recreation of DeBois Bar Graph 

```{r, echo=FALSE, out.width="50%", fig.cap="The image we are trying to recreate"}
knitr::include_graphics("https://github.com/ajstarks/dubois-data-portraits/blob/master/challenge/challenge02/original-plate-10.jpg?raw=true")
```

```{r}
conjugal %>%
  pivot_longer(cols = c(Single, Married, `Divorced and Widowed`), names_to = "marriage_status", values_to = "proportion") %>%
  ggplot(aes(y = fct_relevel(Population, levels = c("Negroes", "Germany")), x=proportion, fill = marriage_status)) +
  geom_col() + 
  facet_wrap(vars(Age), ncol = 1) +
  scale_fill_manual(values = c("darkgreen", "darkgoldenrod2", "darkred"))+
  labs(x = "",
       y= "", 
      fill = "", title = "CONJUGAL CONDITION") +
  theme_minimal()+
  theme(legend.position = "top", 
        plot.background = element_rect(fill = "ivory"),
        plot.title = element_text(family = "mono", hjust = 0.5), 
        panel.grid = element_blank()) + 
  geom_text(aes(label = scales::percent(round(proportion/100, 2))), position = position_stack(.5), cex = 2, color = "white") 
  
```

### Plot Two: Using the Tidy Tuesday tweet data, how many tweets came from each state? 

Clean data and add a location for places that gave a latitude and longitude but did not specify a state or country. 
```{r}
#Filter for where latitude and longitude is missing but there is a recognizable location
tweets %>%
  filter(is.na(lat), !is.na(location)) %>%
  select(location, lat, long, everything()) 

#add an approximate latitude and longitude based on the general location given, remove tweets with no location that can be clearly identified 
tweets <- tweets %>%
  mutate(long = case_when(
    location == "iPhone: 34.704040,-86.722909" ~ -86.722909, 
    location == "Querétaro, México" ~ -100.38806, 
    location == "Jaboatão, PE, Brasil" ~ -34.990741000356685, 
    location == "Forde-Obama Hall" ~ -73.96258343138044, 
    location == "Distrito Federal, México" ~ -99.12989153861437, 
    location == "New York, NY" ~ -73.96461340548562, 
    location == "New York" ~ -73.96461340548562, 
    location == "Hurst, TX" ~ -97.17791347135764, 
    location == "California, USA" ~ -120.34930130639269, 
    location == "Nashville, TN" ~ -86.8045125472499, 
    location == "New Jersey, USA" ~ -74.54365913833645, 
    location == "Seattle, WA" ~ -122.31048750869834, 
    location == "Caracas, Venezuela" ~ -66.85467247534102, 
    TRUE ~ long
  )) %>%
  mutate(lat = case_when(
    location == "iPhone: 34.704040,-86.722909" ~ 34.704040,
    location == "Querétaro, México" ~ 20.58806, 
    location == "Jaboatão, PE, Brasil" ~ -8.122759122720872,
    location == "Forde-Obama Hall" ~ 40.80764104903893,
    location == "Distrito Federal, México" ~ 19.447667314564566, 
    location == "New York, NY" ~ 40.70964250795239, 
    location == "New York" ~ 40.70964250795239,
    location == "Hurst, TX" ~ 32.82941640494242, 
    location == "California, USA" ~ 37.341655286916996,
    location == "Nashville, TN" ~ 36.207370591092904, 
    location == "New Jersey, USA" ~ 40.227194988780425, 
    location == "Seattle, WA" ~ 47.62729088316753, 
    location == "Caracas, Venezuela" ~ 10.458232767034136, 
    TRUE ~ lat
  )) %>%
    select(location, lat, long, everything()) %>%
  filter(!is.na(lat))
```

Continue to clean data. Manually filter for locations that are in the United States and recode these locations to be named states using `case_when()`. 
```{r}
#filter for locations that now have latitude and longitude. Filter for locations in the US
tweets %>%
  group_by(location) %>%
  count()

tweets_us <- tweets %>%
  filter(location %in% c("New York", "Nashville, TN", "Madison, WI", "Albuquerque, NM", "Amherst, MA", "Arlington Heights, IL", "Arvada, CO", "Baltimore, MD", "Boston, MA", "Buffalo, NY", "California", "California, USA", "Cambridge, MA", "Carrboro, NC", "Catawba land", "Chapel Hill, NC", "Charlottesville, VA", "Chicago, IL", "Colorado", "Columbus, OH", "Dallas, TX", "Delaware", "Eugene, OR", "Forde-Obama Hall", "Huntington, NY", "Hurst, TX", "iPhone: 34.704040,-86.722909", "Lafayette, Louisiana", "Merced, CA", "Miami, FL", "Minneapolis, MN", "MIT, Cambridge", "New Jersey, USA", "New York", "New York, NY", "New York, USA", "New Yorker", "Northridge, CA", "Philadelphia", "Philadelphia, PA", "Portland, ME", "Saint Louis, Missouri", "San Diego", "Seattle", "Seattle, WA", "Stanwood, WA", "The City College of New York", "Tx", "Washington, DC"))

#recode these locations to be in state format
tweets_us <- tweets_us %>%
  mutate(location = case_when(
    location == "Nashville, TN" ~ "Tennessee", 
    location == "Madison, WI" ~ "Wisconsin", 
    location == "Albuquerque, NM" ~ "New Mexico", 
    location %in% c("Arlington Heights, IL", "Chicago, IL") ~ "Illinois", 
    location == "Arvada, CO" ~ "Colorado", 
    location == "Baltimore, MD" ~ "Maryland", 
    location %in% c("Boston, MA","Amherst, MA", "Cambridge, MA", "MIT, Cambridge") ~ "Massachusetts", 
    location %in% c("Buffalo, NY", "New York", "New York, NY", "New York, USA", "New Yorker",  "Huntington, NY", "Forde-Obama Hall", "The City College of New York") ~ "New York", 
    location %in% c("California", "California, USA", "Merced, CA", "Northridge, CA", "San Diego") ~ "California", 
    location %in% c("Carrboro, NC", "Chapel Hill, NC", "Catawba land") ~ "North Carolina", 
    location == "Charlottesville, VA" ~ "Virginia", 
    location == "Columbus, OH" ~ "Ohio", 
    location %in% c("Dallas, TX", "Hurst, TX", "Tx") ~ "Texas", 
    location == "Eugene, OR" ~ "Oregon", 
    location == "Lafayette, Louisiana" ~ "Louisiana", 
    location == "iPhone: 34.704040,-86.722909" ~ "Alabama", 
    location == "Miami, FL" ~ "Florida", 
    location == "Minneapolis, MN" ~ "Minnesota", 
    location %in% c("New Jersey, USA") ~ "New Jersey", 
    location %in% c("Philadelphia", "Philadelphia, PA") ~ "Pennsylvania", 
    location == "Portland, ME" ~ "Maine",
    location == "Saint Louis, Missouri" ~ "Missouri", 
    location %in% c("Seattle", "Seattle, WA", "Stanwood, WA") ~ "Washington", 
    TRUE ~ location
  )) %>%
  mutate(location = str_to_lower(location))
```

Create the map!!! :) 
```{r}
tweets_grouped <- tweets_us %>%
  group_by(location) %>%
  count()

#US states map information - coordinates used to draw borders
states_map <- map_data("state")


# map that colors state by number of tweets
tweets_grouped %>% 
  ggplot() +
  geom_map(map = states_map,
           aes(map_id = location,
               fill = n)) +
  expand_limits(x = states_map$long, y = states_map$lat) + 
  labs(title = "Number of US tweets per state for 2021 #DuBoisChallenge", fill = "", caption = "States that did not tweet are left white. \nPlot created by Erin Franke, data from #DuBoisChalllenge 2021 Twitter Metrics by Sekou Tyler")+
  annotate(geom = "text", x = -80.4 , y=45, label = "New York had 143 tweets, \n87.4% of which were by \n@AlDatavizguy! Next closest was \nTennessee at 33 tweets", fontface="bold", cex = 2) + 
  theme_map()
```
